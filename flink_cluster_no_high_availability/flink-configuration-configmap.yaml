apiVersion: v1
kind: Namespace
metadata:
  name: flink
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: flink-config
  namespace: flink
  labels:
    app: flink
data:
  flink-conf.yaml: |+
    # env.java.opts: -Dlog4j2.configuration=file:/opt/flink/conf/log4j-console.properties

    # cluster cfg
    jobmanager.rpc.address: flink-jobmanager
    taskmanager.numberOfTaskSlots: 4
    blob.server.port: 6124
    jobmanager.rpc.port: 6123
    taskmanager.rpc.port: 6122
    jobmanager.memory.process.size: 1600m
    taskmanager.memory.process.size: 1728m
    parallelism.default: 2

    # backend cfg
    state.checkpoints.dir: s3a://apache-flink/checkpoints
    state.backend.fs.checkpointdir: s3a://apache-flink/checkpoints
    state.backend: filesystem
    execution.checkpointing.externalized-checkpoint-retention: RETAIN_ON_CANCELLATION

    # checkpoints cfg
    fs.s3a.path.style.access: true
    fs.s3a.access.key: minio
    fs.s3a.secret.key: minio123
    fs.s3a.endpoint: http://minio-service.minio.svc.cluster.local:9000
  log4j-console.properties: |+
    # This affects logging for both user code and Flink
    rootLogger.level = INFO
    rootLogger.appenderRef.console.ref = ConsoleAppender
    rootLogger.appenderRef.rolling.ref = RollingFileAppender

    # Uncomment this if you want to _only_ change Flink's logging
    logger.flink.name = org.apache.flink
    logger.flink.level = INFO

    # The following lines keep the log level of common libraries/connectors on
    # log level INFO. The root logger does not override this. You have to manually
    # change the log levels here.
    # logger.pekko.name = org.apache.pekko
    # logger.pekko.level = INFO
    # logger.kafka.name= org.apache.kafka
    # logger.kafka.level = INFO
    # logger.hadoop.name = org.apache.hadoop
    # logger.hadoop.level = INFO
    # logger.zookeeper.name = org.apache.zookeeper
    # logger.zookeeper.level = INFO

    # Log all infos to the console
    appender.console.name = ConsoleAppender
    appender.console.type = CONSOLE
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n

    # Log all infos in the given rolling file
    appender.rolling.name = RollingFileAppender
    appender.rolling.type = RollingFile
    appender.rolling.append = false
    appender.rolling.fileName = ${sys:log.file}
    appender.rolling.filePattern = ${sys:log.file}.%i
    appender.rolling.layout.type = PatternLayout
    appender.rolling.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n
    appender.rolling.policies.type = Policies
    appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
    appender.rolling.policies.size.size=100MB
    appender.rolling.strategy.type = DefaultRolloverStrategy
    appender.rolling.strategy.max = 10

    # Suppress the irrelevant (wrong) warnings from the Netty channel handler
    logger.netty.name = org.jboss.netty.channel.DefaultChannelPipeline
    logger.netty.level = OFF

    # Log output from org.apache.flink.kubernetes to the console.
    logger.kubernetes.name = org.apache.flink.kubernetes
    logger.kubernetes.level = INFO
    logger.kubernetes.appenderRef.console.ref = ConsoleAppender

    # Log all infos in the given file
    appender.main.name = MainAppender
    appender.main.type = RollingFile
    appender.main.append = true
    appender.main.fileName = ${sys:log.file}
    appender.main.filePattern = ${sys:log.file}.%i
    appender.main.layout.type = PatternLayout
    appender.main.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n
    appender.main.policies.type = Policies
    appender.main.policies.size.type = SizeBasedTriggeringPolicy
    appender.main.policies.size.size = 100MB
    appender.main.policies.startup.type = OnStartupTriggeringPolicy
    appender.main.strategy.type = DefaultRolloverStrategy
    appender.main.strategy.max = 10